{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f5c37a2-a9c8-45a9-828a-14ddeacb630f",
   "metadata": {},
   "source": [
    "# Train Anamoly Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0a8f2d-22f4-46d9-888f-5dd6a6273dc0",
   "metadata": {},
   "source": [
    "## Initialize Parameters from Data-processing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68ea7100-a648-4e01-be7c-ffbe1084f175",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e254d96f-ca26-47df-88ca-ea3ba11a1a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install tensorflow\n",
    "# !pip install tensorflow-io\n",
    "# !pip install tf-models-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4324b96-94db-48a4-b734-2683a3eeb59a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6135e658-b50f-4ddc-832f-b474c9882e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54d1b7a7-bb9a-46ed-99d3-562344efbf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = os.getenv(\"BUCKET_NAME\", \"ml-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281fd4ca-ec0e-4df3-86db-7e19024ecc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"AWS_ACCESS_KEY_ID\"] = \"console\"\n",
    "# os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"console123\"\n",
    "# os.environ[\"AWS_REGION\"] = \"us-east-1\"\n",
    "# os.environ[\"S3_ENDPOINT\"] = \"https://minio.svc.cluster.bla\"\n",
    "# os.environ[\"S3_USE_HTTPS\"] = \"1\"\n",
    "# os.environ[\"S3_VERIFY_SSL\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d919af-bd8d-4d4b-9bec-68c8a70a29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_io\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from official.nlp import optimization\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea887882-d58f-4881-9423-a0d21ffe6c79",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "np_data = np.load('processed_train_data.npz', allow_pickle=True)\n",
    "x_tr = np_data['x_train']\n",
    "y_tr = np_data['y_train']\n",
    "embed_dim = 768\n",
    "max_len = 75\n",
    "fine_tune_model_remote_path = None\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "model_name = \"bert_hdfs_weights.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0ba9b-f6cc-4e12-9539-4a74290c0240",
   "metadata": {},
   "source": [
    "## Helper Functions for Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dc6bea-ba32-47cc-91b9-2b3897fb92c3",
   "metadata": {},
   "source": [
    "### Create positional embedding layer (Custom Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d037a5-4dfe-435f-8a04-49fb78b8d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "class PositionEmbedding(layers.Layer):\n",
    "    def __init__(self, max_len, vocab_size, embed_dim):\n",
    "        super(PositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_encoding = positional_encoding(max_len,\n",
    "                                                embed_dim)\n",
    " \n",
    "    def call(self, x):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c4e222-b57d-4289-8d11-66dff66c4ed3",
   "metadata": {},
   "source": [
    "### Batch generator class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c5b2360-c356-42d4-a6f6-6ba96687919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, X, Y, batch_size):\n",
    "        self.X, self.Y = X, Y\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(self.batch_size)\n",
    "        dummy = np.zeros(shape=(embed_dim,))\n",
    "        x = self.X[idx * self.batch_size:min((idx + 1) * self.batch_size, len(self.X))]\n",
    "        X = np.zeros((len(x), max_len, embed_dim))\n",
    "        Y = np.zeros((len(x), 2))\n",
    "        item_count = 0\n",
    "        for i in range(idx * self.batch_size, min((idx + 1) * self.batch_size, len(self.X))):\n",
    "            x = self.X[i]\n",
    "            if len(x) > max_len:\n",
    "                x = x[-max_len:]\n",
    "            x = np.pad(np.array(x), pad_width=((max_len - len(x), 0), (0, 0)), mode='constant',\n",
    "                       constant_values=0)\n",
    "            X[item_count] = np.reshape(x, [max_len, embed_dim])\n",
    "            Y[item_count] = self.Y[i]\n",
    "            item_count += 1\n",
    "        return X[:], Y[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e64b7dc-8bd8-4536-8114-c24bb1ee68e2",
   "metadata": {},
   "source": [
    "### Anomaly Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "341cace1-89e7-442e-a449-56c9fe2d7626",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim), ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    \n",
    "def transformer_classifer(embed_dim, ff_dim, max_len, num_heads, dropout=0.1):\n",
    "    inputs = layers.Input(shape=(max_len, embed_dim))\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "    embedding_layer = PositionEmbedding(100, 2000, embed_dim)\n",
    "    x = embedding_layer(inputs)\n",
    "    x = transformer_block(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ceeff-aa21-4ae8-bda9-0783b0247d7d",
   "metadata": {},
   "source": [
    "## Helper functions for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec8227f8-ef49-48e5-9e10-0dc6f78bc105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(training_generator, validate_generator, num_train_samples, num_val_samples, batch_size,\n",
    "                    epoch_num, model_name=None):\n",
    "    epochs = epoch_num\n",
    "    steps_per_epoch = num_train_samples\n",
    "    num_train_steps = steps_per_epoch * epochs\n",
    "    num_warmup_steps = int(0.1 * num_train_steps)\n",
    "\n",
    "    init_lr = 3e-4\n",
    "    optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                              num_train_steps=num_train_steps,\n",
    "                                              num_warmup_steps=num_warmup_steps,\n",
    "                                              optimizer_type='adamw')\n",
    "\n",
    "    loss_object = SparseCategoricalCrossentropy()\n",
    "\n",
    "    model = transformer_classifer(768, ff_dim=2048, max_len=75, num_heads=12, dropout=0.1)\n",
    "\n",
    "    # model.load_weights(\"hdfs_transformer.hdf5\")\n",
    "\n",
    "    model.compile(loss=loss_object, metrics=['accuracy'],\n",
    "                  optimizer=optimizer)\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    # checkpoint\n",
    "    filepath = model_name\n",
    "    checkpoint = ModelCheckpoint(filepath,\n",
    "                                 monitor='val_accuracy',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True,\n",
    "                                 mode='max',\n",
    "                                 save_weights_only=True)\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto',\n",
    "        baseline=None, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    logdir = f\"s3://{bucket}/logs/hdfs-tb/run-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "    callbacks_list = [checkpoint, tensorboard_callback, early_stop]\n",
    "\n",
    "    history = model.fit(training_generator,\n",
    "                        steps_per_epoch=int(num_train_samples / batch_size),\n",
    "                        epochs=epoch_num,\n",
    "                        verbose=1,\n",
    "                        validation_data=validate_generator,\n",
    "                        validation_steps=int(num_val_samples / batch_size),\n",
    "                        workers=16,\n",
    "                        max_queue_size=32,\n",
    "                        callbacks=callbacks_list,\n",
    "                        shuffle=True\n",
    "                        )\n",
    "    return model, history\n",
    "\n",
    "\n",
    "def train(X, Y, epoch_num, batch_size, model_file=None):\n",
    "    X, Y = shuffle(X, Y)\n",
    "    n_samples = len(X)\n",
    "    train_x, train_y = X[:int(n_samples * 90 / 100)], Y[:int(n_samples * 90 / 100)]\n",
    "    val_x, val_y = X[int(n_samples * 90 / 100):], Y[int(n_samples * 90 / 100):]\n",
    "\n",
    "    training_generator, num_train_samples = BatchGenerator(train_x, train_y, batch_size), len(train_x)\n",
    "    validate_generator, num_val_samples = BatchGenerator(val_x, val_y, batch_size), len(val_x)\n",
    "\n",
    "    print(\"Number of training samples: {0} - Number of validating samples: {1}\".format(num_train_samples,\n",
    "                                                                                       num_val_samples))\n",
    "\n",
    "    model, history = train_generator(\n",
    "        training_generator,\n",
    "        validate_generator,\n",
    "        num_train_samples,\n",
    "        num_val_samples,\n",
    "        batch_size,\n",
    "        epoch_num,\n",
    "        model_name=model_file)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd78708-38ca-47dc-bf9d-fa60fcd45a25",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a45a9034-323f-4944-8cd1-93d9b3505adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 280 - Number of validating samples: 32\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 75, 768)]         0         \n",
      "                                                                 \n",
      " position_embedding (Positio  (None, 75, 768)          0         \n",
      " nEmbedding)                                                     \n",
      "                                                                 \n",
      " transformer_block (Transfor  (None, 75, 768)          31491584  \n",
      " merBlock)                                                       \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 768)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                24608     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,516,258\n",
      "Trainable params: 31,516,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Layer PositionEmbedding has arguments ['max_len', 'vocab_size', 'embed_dim']\n",
      "in `__init__` and therefore must override `get_config()`.\n",
      "\n",
      "Example:\n",
      "\n",
      "class CustomLayer(keras.layers.Layer):\n",
      "    def __init__(self, arg1, arg2):\n",
      "        super().__init__()\n",
      "        self.arg1 = arg1\n",
      "        self.arg2 = arg2\n",
      "\n",
      "    def get_config(self):\n",
      "        config = super().get_config()\n",
      "        config.update({\n",
      "            \"arg1\": self.arg1,\n",
      "            \"arg2\": self.arg2,\n",
      "        })\n",
      "        return config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Layer PositionEmbedding has arguments ['max_len', 'vocab_size', 'embed_dim']\n",
      "in `__init__` and therefore must override `get_config()`.\n",
      "\n",
      "Example:\n",
      "\n",
      "class CustomLayer(keras.layers.Layer):\n",
      "    def __init__(self, arg1, arg2):\n",
      "        super().__init__()\n",
      "        self.arg1 = arg1\n",
      "        self.arg2 = arg2\n",
      "\n",
      "    def get_config(self):\n",
      "        config = super().get_config()\n",
      "        config.update({\n",
      "            \"arg1\": self.arg1,\n",
      "            \"arg2\": self.arg2,\n",
      "        })\n",
      "        return config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2079 - accuracy: 0.9844WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 21s 5s/step - loss: 0.2079 - accuracy: 0.9844\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1450 - accuracy: 0.9844WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 19s 5s/step - loss: 0.1450 - accuracy: 0.9844\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9769WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 0.1236 - accuracy: 0.9769\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9815WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 0.1132 - accuracy: 0.9815\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1420 - accuracy: 0.9769WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 0.1420 - accuracy: 0.9769\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.9815WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 0.1066 - accuracy: 0.9815\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1185 - accuracy: 0.9769WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 0.1185 - accuracy: 0.9769\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.9769WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 0.1106 - accuracy: 0.9769\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9907WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 0.0629 - accuracy: 0.9907\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1077 - accuracy: 0.9769WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 0.1077 - accuracy: 0.9769\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1141 - accuracy: 0.9769WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 5s/step - loss: 0.1141 - accuracy: 0.9769\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.9815WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 0.1057 - accuracy: 0.9815\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.9844WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 19s 5s/step - loss: 0.0757 - accuracy: 0.9844\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9769WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 0.1152 - accuracy: 0.9769\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9844WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 19s 5s/step - loss: 0.0869 - accuracy: 0.9844\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9769WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 0.1038 - accuracy: 0.9769\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 19s 5s/step - loss: 0.0625 - accuracy: 0.9805\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1239 - accuracy: 0.9769WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 5s/step - loss: 0.1239 - accuracy: 0.9769\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.9815WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 0.0908 - accuracy: 0.9815\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1496 - accuracy: 0.9769WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 0.1496 - accuracy: 0.9769\n"
     ]
    }
   ],
   "source": [
    "model, history = train(x_tr, y_tr, epochs, batch_size, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70694b4c-404c-4184-8200-5e1d9d394e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5388b589-2a10-423a-b5e2-4803b9decde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "\n",
      "DONE TRAINING\n",
      "/home/jovyan/minio-ml/log-trainer\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*100)\n",
    "print(\"\")\n",
    "print(\"DONE TRAINING\")\n",
    "print(os.getcwd())\n",
    "print(\"\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42caf0cb-91f2-41eb-ada6-120c497799f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_test_data.npz\n",
      "minio-train-model.ipynb\n",
      "sample-secret.yaml\n",
      "NeuralLog-trainer.pipeline\n",
      "processed_train_data.npz\n",
      "data-bert.npz\n",
      "minio-evaluate-model.ipynb\n",
      "requirements.txt\n",
      "minio-logs-data-processing.ipynb\n",
      "mlpipeline-metrics.json\n"
     ]
    }
   ],
   "source": [
    "files = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
    "for f in files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f667315d-97c7-4eda-9183-f343382c7cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'metrics': []}\n",
    "for key, value in history.history.items():\n",
    "    metrics['metrics'].append({\n",
    "        'name': key,\n",
    "        'numberValue': value[0]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b503daca-3a90-4003-ae1b-b54d9353d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('mlpipeline-metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645c4d81-9b60-4491-8fe5-f0ee7977c267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318119f7-ef74-437a-9796-90e2b962a408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
