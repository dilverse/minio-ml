{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30b1053a-1cf1-4cb3-a267-338741c0bc24",
   "metadata": {},
   "source": [
    "# Minio - Prepare Models for Deploy (NeuralLog and BERT Embedding Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bf66190-4d87-4283-b5d1-caafeba993ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "83a52d6f-f9f9-4265-8e9b-48407b237bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import fsspec\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e4832b1-fdec-4af6-ba40-d9651efa063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = os.getenv(\"BUCKET_NAME\",\"ml-data\")\n",
    "minio_endpoint = os.getenv(\"S3_ENDPOINT\",\"https://YOUR_MINIO_SERVER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b255da6f-0856-4400-8a5d-74694bc9653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize minio config for fsspec to be used downstream\n",
    "fsspec.config.conf = {\n",
    "  \"s3\":\n",
    "  {\n",
    "    \"key\": os.getenv(\"AWS_ACCESS_KEY_ID\", \"console\"),\n",
    "    \"secret\": os.getenv(\"AWS_SECRET_ACCESS_KEY\", \"console123\"),\n",
    "    \"client_kwargs\": {\n",
    "      \"endpoint_url\": os.getenv(\"S3_ENDPOINT\", minio_endpoint)\n",
    "    }\n",
    "  }\n",
    "}\n",
    "s3 = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f334f501-4be9-4e71-b1a9-78f83adbf093",
   "metadata": {},
   "source": [
    "## BERT Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a925ec78-6d15-4f71-b1f7-f0eb45d89165",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = s3.ls(f\"{bucket}/logs/saved_models/tfs/\")\n",
    "bert_model_exists = False\n",
    "for model_path in models_list:\n",
    "    split_path = model_path.split(\"/\")\n",
    "    if split_path[-1] == 'bert_model':\n",
    "        bert_model_exists = True\n",
    "        break\n",
    "\n",
    "if not bert_model_exists:\n",
    "    from transformers import TFBertModel\n",
    "    model_remote_path = f\"s3://{bucket}/logs/saved_models/bert-base-uncased/\"\n",
    "    s3.download(rpath=model_remote_path, lpath=\"bert-base-uncased\", recursive=True)\n",
    "    bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    tf.saved_model.save(bert_model, 'bert_model/1')\n",
    "    \n",
    "    s3.put('bert_model/', f\"{bucket}/logs/saved_models/tfs\", recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35017f9b-c5f7-487b-a4c1-f8e91ecdbc7c",
   "metadata": {},
   "source": [
    "## Anomaly Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8aad9c12-4d32-4fef-aa51-c4b3274eea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = s3.ls(f\"{bucket}/logs/saved_models/tfs/log_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2bb54765-b7f9-4eec-90f3-d74eb3a8eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from official.nlp import optimization\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim), ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    \n",
    "def transformer_classifer(embed_dim, ff_dim, max_len, num_heads, dropout=0.1):\n",
    "    inputs = layers.Input(shape=(max_len, embed_dim), name='input_1')\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "    embedding_layer = PositionEmbedding(100, 2000, embed_dim)\n",
    "    x = embedding_layer(inputs)\n",
    "    x = transformer_block(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "class PositionEmbedding(layers.Layer):\n",
    "    def __init__(self, max_len, vocab_size, embed_dim):\n",
    "        super(PositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_encoding = positional_encoding(max_len,\n",
    "                                                embed_dim)\n",
    " \n",
    "    def call(self, x):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5f7cb1e1-7932-433f-80fb-16aa7771afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    init_lr = 3e-4\n",
    "    optimizer = tfa.optimizers.AdamW(init_lr)\n",
    "    model = transformer_classifer(768, ff_dim=2048, max_len=75, num_heads=12, dropout=0.1)\n",
    "    loss_object = SparseCategoricalCrossentropy()\n",
    "    model.load_weights(path)\n",
    "    model.compile(loss=loss_object, metrics=['accuracy'],\n",
    "                  optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a782b716-4088-491d-8b26-02c4fa16bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"bert_hdfs_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e928392b-fb62-4b85-a025-b873ec8f95cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = int(model_list[-1].split(\"/\")[-1])\n",
    "new_version = f\"{version + 1}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6a0350a7-f8ec-4a34-9f59-964102226073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.embedding.Embedding object at 0x7fa1110d2c70>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.embedding.Embedding object at 0x7fa1110d2c70>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as multi_head_attention_5_layer_call_fn, multi_head_attention_5_layer_call_and_return_conditional_losses, layer_normalization_10_layer_call_fn, layer_normalization_10_layer_call_and_return_conditional_losses, layer_normalization_11_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: log_model/5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: log_model/5/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, f'log_model/{new_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aba69a2d-8b67-4f46-b798-09385392fdf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.put('log_model/', f\"{bucket}/logs/saved_models/tfs\", recursive=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
