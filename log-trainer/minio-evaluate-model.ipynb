{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f5c37a2-a9c8-45a9-828a-14ddeacb630f",
   "metadata": {},
   "source": [
    "# Train Anamoly Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0a8f2d-22f4-46d9-888f-5dd6a6273dc0",
   "metadata": {},
   "source": [
    "## Initialize Parameters from Data-processing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ea7100-a648-4e01-be7c-ffbe1084f175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.5.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: papermill in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (2.4.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting s3fs\n",
      "  Downloading s3fs-2022.8.2-py3-none-any.whl (27 kB)\n",
      "Collecting tf-models-official\n",
      "  Downloading tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
      "Collecting numpy>=1.18.5\n",
      "  Downloading numpy-1.23.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (2021.3)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.37.1-py3-none-any.whl (957 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m957.2/957.2 kB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (2.4.7)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.2.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (21.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from papermill->-r requirements.txt (line 3)) (2.26.0)\n",
      "Requirement already satisfied: tqdm>=4.32.2 in /opt/conda/lib/python3.8/site-packages (from papermill->-r requirements.txt (line 3)) (4.62.3)\n",
      "Requirement already satisfied: nbclient>=0.2.0 in /opt/conda/lib/python3.8/site-packages (from papermill->-r requirements.txt (line 3)) (0.5.4)\n",
      "Requirement already satisfied: ansiwrap in /opt/conda/lib/python3.8/site-packages (from papermill->-r requirements.txt (line 3)) (0.8.4)\n",
      "Requirement already satisfied: nbformat>=5.1.2 in /opt/conda/lib/python3.8/site-packages (from papermill->-r requirements.txt (line 3)) (5.4.0)\n",
      "Requirement already satisfied: tenacity in /opt/conda/lib/python3.8/site-packages (from papermill->-r requirements.txt (line 3)) (8.0.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from papermill->-r requirements.txt (line 3)) (5.4.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from papermill->-r requirements.txt (line 3)) (0.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from papermill->-r requirements.txt (line 3)) (8.1.3)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.9.13-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.3/772.3 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.7/120.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiobotocore~=2.4.0\n",
      "  Downloading aiobotocore-2.4.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec==2022.8.2\n",
      "  Downloading fsspec-2022.8.2-py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.8/140.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /opt/conda/lib/python3.8/site-packages (from tf-models-official->-r requirements.txt (line 6)) (1.12.11)\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting kaggle>=1.3.9\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting Cython\n",
      "  Downloading Cython-0.29.32-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow~=2.9.0\n",
      "  Downloading tensorflow-2.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m458.7/511.8 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d919af-bd8d-4d4b-9bec-68c8a70a29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from official.nlp import optimization\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea887882-d58f-4881-9423-a0d21ffe6c79",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "np_data = np.load('processed_test_data.npz', allow_pickle=True)\n",
    "x_te = np_data['x_test']\n",
    "y_te = np_data['y_test']\n",
    "embed_dim = 768\n",
    "max_len = 75\n",
    "fine_tune_model_remote_path = None\n",
    "batch_size = 64\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0ba9b-f6cc-4e12-9539-4a74290c0240",
   "metadata": {},
   "source": [
    "## Helper Functions for Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dc6bea-ba32-47cc-91b9-2b3897fb92c3",
   "metadata": {},
   "source": [
    "### Create positional embedding layer (Custom Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d037a5-4dfe-435f-8a04-49fb78b8d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "class PositionEmbedding(layers.Layer):\n",
    "    def __init__(self, max_len, vocab_size, embed_dim):\n",
    "        super(PositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_encoding = positional_encoding(max_len,\n",
    "                                                embed_dim)\n",
    " \n",
    "    def call(self, x):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c4e222-b57d-4289-8d11-66dff66c4ed3",
   "metadata": {},
   "source": [
    "### Batch generator class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5b2360-c356-42d4-a6f6-6ba96687919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, X, Y, batch_size):\n",
    "        self.X, self.Y = X, Y\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(self.batch_size)\n",
    "        dummy = np.zeros(shape=(embed_dim,))\n",
    "        x = self.X[idx * self.batch_size:min((idx + 1) * self.batch_size, len(self.X))]\n",
    "        X = np.zeros((len(x), max_len, embed_dim))\n",
    "        Y = np.zeros((len(x), 2))\n",
    "        item_count = 0\n",
    "        for i in range(idx * self.batch_size, min((idx + 1) * self.batch_size, len(self.X))):\n",
    "            x = self.X[i]\n",
    "            if len(x) > max_len:\n",
    "                x = x[-max_len:]\n",
    "            x = np.pad(np.array(x), pad_width=((max_len - len(x), 0), (0, 0)), mode='constant',\n",
    "                       constant_values=0)\n",
    "            X[item_count] = np.reshape(x, [max_len, embed_dim])\n",
    "            Y[item_count] = self.Y[i]\n",
    "            item_count += 1\n",
    "        return X[:], Y[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e64b7dc-8bd8-4536-8114-c24bb1ee68e2",
   "metadata": {},
   "source": [
    "### Anomaly Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341cace1-89e7-442e-a449-56c9fe2d7626",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim), ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    \n",
    "def transformer_classifer(embed_dim, ff_dim, max_len, num_heads, dropout=0.1):\n",
    "    inputs = layers.Input(shape=(max_len, embed_dim))\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "    embedding_layer = PositionEmbedding(100, 2000, embed_dim)\n",
    "    x = embedding_layer(inputs)\n",
    "    x = transformer_block(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ceeff-aa21-4ae8-bda9-0783b0247d7d",
   "metadata": {},
   "source": [
    "## Helper functions for evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3250d5-734f-4938-bf45-e8f9fca7aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    init_lr = 3e-4\n",
    "    optimizer = tfa.optimizers.AdamW(init_lr)\n",
    "    model = transformer_classifer(768, ff_dim=2048, max_len=75, num_heads=12, dropout=0.1)\n",
    "    loss_object = SparseCategoricalCrossentropy()\n",
    "    model.load_weights(path)\n",
    "    model.compile(loss=loss_object, metrics=['accuracy'],\n",
    "                  optimizer=optimizer)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd78708-38ca-47dc-bf9d-fa60fcd45a25",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de756b7c-68b9-4857-bc80-d7f2fdd83572",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"hdfs_transformer.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31962c29-2689-441c-9109-54c84e016964",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(BatchGenerator(x_te, y_te, batch_size=64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734ac538-0041-4a71-ac82-6585cf27dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"saved_model\")\n",
    "# new_model = keras.models.load_model('save_models/', custom_objects={'TransformerBlock': TransformerBlock, \"PositionEmbedding\": PositionEmbedding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9d0eb5-fb06-4dc9-b4ff-b47ded816820",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'metrics': [\n",
    "        {\"name\": \"evaluation_loss\",\n",
    "         \"numberValue\": score[0]},\n",
    "        {\"name\": \"evaluation_accuracy\",\n",
    "         \"numberValue\": score[1]},\n",
    "    ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7716fbfc-7179-4065-bab1-6e762a0ae430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('mlpipeline-metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dc8bbb-2ccb-4b4a-bae7-aaba8685fdfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
